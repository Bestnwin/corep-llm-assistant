# ğŸ§  COREP RAG Assistant

[![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)](https://www.python.org/) 
[![Gradio](https://img.shields.io/badge/Gradio-6.5.1-orange?logo=gradio)](https://gradio.app/)
[![Transformers](https://img.shields.io/badge/Transformers-4.57.6-purple?logo=huggingface)](https://huggingface.co/docs/transformers/index)

- A **RAG (Retrieval-Augmented Generation)** assistant for analyzing PDFs and answering regulatory questions (like EBA/PRA COREP reports).  

- Upload PDFs to the `data/` folder, build a vector database using **FAISS**, and ask questions using **FLAN-T5** and **HuggingFace embeddings**.  

---

## ğŸ“ Project Structure
```bash
corep-assistant/
â”‚
â”œâ”€ data/ # Place your PDFs here
â”œâ”€ docs/ # Optional documentation files
â”œâ”€ faiss_index/ # FAISS database will be saved here
â”‚ â”œâ”€ index.faiss
â”‚ â””â”€ index.pkl
â”œâ”€ vector_db/ # Optional, for future vector storage
â”‚
â”œâ”€ main.py # Command-line interface for building DB & querying
â”œâ”€ app.py # Gradio web interface
â”œâ”€ rag_pipeline.py # Core functions: load docs, build DB, query DB
â”œâ”€ requirements.txt # Python dependencies
â”œâ”€ README.md # This file
â””â”€ .env # Optional environment variables
```

---

## âš¡ Features

- Load PDFs from `data/` and clean text automatically
- Split text into chunks for embedding
- Build a **FAISS vector database**
- Query your PDFs using **natural language questions**
- Answers generated using **FLAN-T5-small**
- Web interface via **Gradio** for easy use

---

## ğŸ›  Installation

1. Clone this repository:

```bash
git clone <your-repo-url>
cd corep-assistant
```
## Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate      # Linux / Mac
venv\Scripts\activate         # Windows
```
## Install dependencies:
```bash
pip install -r requirements.txt
```
## ğŸ’» Running from Command Line

ğŸ’» CLI Mode â€” Regulatory Reporting Prototype Workflow

This mode implements the core objective of the PRA prototype.

## Given a natural-language question and scenario description, the CLI:

### 1ï¸âƒ£ Retrieves relevant PRA Rulebook / COREP instruction text
### 2ï¸âƒ£ Generates structured LLM output aligned to a predefined schema
### 3ï¸âƒ£ Returns machine-readable data (JSON-style output)
### 4ï¸âƒ£ Enables mapping into template extracts
### 5ï¸âƒ£ Supports validation or downstream automation

### This mode demonstrates:

- End-to-end regulatory reporting assistance

- Structured data generation for COREP templates

- Audit-friendly traceable outputs

- Prototype feasibility for automation pipelines

### Build database:
```bash
python main.py
```
Choose 1 to build the FAISS database from PDFs in data/.
Choose 2 and type your question.
Type exit to quit.

## ğŸŒ Running the Gradio Web App
1.Make sure the FAISS database is built.
2.Run:
```bash
python app.py
```
3.Open your browser at:
```bash
http://localhost:7860
```

4. Features:
- Build / update the database
- Type questions and get answers along with source pages

## ğŸ“„ Usage Notes

- Place all PDFs in the data/ folder before building the database.

- The database will be saved to faiss_index/.

- If no answer is found in the documents, the assistant will return "Not found in document".

- You can increase chunk_size in rag_pipeline.py for larger text chunks if needed.

## âš™ï¸ Dependencies
- Key Python libraries:

- transformers

- torch

- faiss-cpu

- langchain, langchain-huggingface, langchain-community

- gradio

- PyPDF2 or pypdf

See full requirements.txt for all dependencies

## ğŸ“Œ Tips

- For faster performance, use a GPU if available by changing device=-1 to device=0 in the pipeline.

- Regularly update requirements.txt with:

```bash
pip freeze > requirements.txt
```
## ğŸ™‹â€â™‚ï¸ Author
Akshit Sharma|akshit6299@outlook.com|Bestnwin


